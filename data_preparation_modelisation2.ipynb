{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Loading the Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, StandardScaler, OneHotEncoder, PolynomialFeatures, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier, Ridge, Lasso, ElasticNet\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Reading the Data and performing Basic Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>...</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "      <td>2014.322954</td>\n",
       "      <td>6.574423</td>\n",
       "      <td>15.688197</td>\n",
       "      <td>0.677046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>...</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "      <td>0.467616</td>\n",
       "      <td>3.115308</td>\n",
       "      <td>8.635063</td>\n",
       "      <td>0.467616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              price      bedrooms     bathrooms   sqft_living      sqft_lot  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  2.161300e+04   \n",
       "mean   5.400881e+05      3.370842      2.114757   2079.899736  1.510697e+04   \n",
       "std    3.671272e+05      0.930062      0.770163    918.440897  4.142051e+04   \n",
       "min    7.500000e+04      0.000000      0.000000    290.000000  5.200000e+02   \n",
       "25%    3.219500e+05      3.000000      1.750000   1427.000000  5.040000e+03   \n",
       "50%    4.500000e+05      3.000000      2.250000   1910.000000  7.618000e+03   \n",
       "75%    6.450000e+05      4.000000      2.500000   2550.000000  1.068800e+04   \n",
       "max    7.700000e+06     33.000000      8.000000  13540.000000  1.651359e+06   \n",
       "\n",
       "             floors    waterfront          view     condition         grade  \\\n",
       "count  21613.000000  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean       1.494309      0.007542      0.234303      3.409430      7.656873   \n",
       "std        0.539989      0.086517      0.766318      0.650743      1.175459   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      3.000000      7.000000   \n",
       "50%        1.500000      0.000000      0.000000      3.000000      7.000000   \n",
       "75%        2.000000      0.000000      0.000000      4.000000      8.000000   \n",
       "max        3.500000      1.000000      4.000000      5.000000     13.000000   \n",
       "\n",
       "       ...  yr_renovated       zipcode           lat          long  \\\n",
       "count  ...  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   ...     84.402258  98077.939805     47.560053   -122.213896   \n",
       "std    ...    401.679240     53.505026      0.138564      0.140828   \n",
       "min    ...      0.000000  98001.000000     47.155900   -122.519000   \n",
       "25%    ...      0.000000  98033.000000     47.471000   -122.328000   \n",
       "50%    ...      0.000000  98065.000000     47.571800   -122.230000   \n",
       "75%    ...      0.000000  98118.000000     47.678000   -122.125000   \n",
       "max    ...   2015.000000  98199.000000     47.777600   -121.315000   \n",
       "\n",
       "       sqft_living15     sqft_lot15          year         month           day  \\\n",
       "count   21613.000000   21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean     1986.552492   12768.455652   2014.322954      6.574423     15.688197   \n",
       "std       685.391304   27304.179631      0.467616      3.115308      8.635063   \n",
       "min       399.000000     651.000000   2014.000000      1.000000      1.000000   \n",
       "25%      1490.000000    5100.000000   2014.000000      4.000000      8.000000   \n",
       "50%      1840.000000    7620.000000   2014.000000      6.000000     16.000000   \n",
       "75%      2360.000000   10083.000000   2015.000000      9.000000     23.000000   \n",
       "max      6210.000000  871200.000000   2015.000000     12.000000     31.000000   \n",
       "\n",
       "          year_rate  \n",
       "count  21613.000000  \n",
       "mean       0.677046  \n",
       "std        0.467616  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_cleaning_analysis.csv')\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('nb_days', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Creating the Training and Test Datasets  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diviser data set en training set et test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÃ©parer la target (i.e. price) des autres valeurs (X)\n",
    "X = df.drop('price', axis=1)\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split le dataset en spÃ©cifiant le pourcentage de data Ã  garder dans le test dataset\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Creating Arrays for the Features and the Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage de chaque classe de la variable y en une valeur numÃ©rique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour les variables qui ont un lien hiÃ©rarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the exercise purpose... Because it fits strings better\n",
    "y = np.array(df.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fonctionne avec le y et non le X cÃ d plusieurs variables. Dans ce cas, utiliser OrdinalEncoding(X)\n",
    "encoder.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(y)\n",
    "# ou directement encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pour dÃ©coder les donnÃ©es\n",
    "encoder.inverse_transform(np.array([0,0,2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pour les variables catÃ©gorielles, i.e. qui n'ont pas de lien hiÃ©rarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21613x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21613 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CrÃ©er une matrix compressÃ©e\n",
    "encoder = LabelBinarizer(sparse_output=True)\n",
    "encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SÃ©lection des colonnes Ã  encoder et Ã  standardiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÃ©lection des colonnes numÃ©riques\n",
    "num_col = list(X.select_dtypes(include=[float, int]).columns)\n",
    "\n",
    "# SÃ©lection des colonnes catÃ©gorielles\n",
    "cat_col = list(X.select_dtypes(include=[object]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ou preprocessing\n",
    "my_col_trans = ColumnTransformer([\n",
    "    (\"one_hot\", OneHotEncoder(), cat_col),\n",
    "    (\"scaling\", StandardScaler(), num_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipe=make_pipeline(my_col_trans, LinearRegression(), PolynomialFeatures())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Build, Predict and Evaluate the Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettre les valeurs quantitatives sur la mÃªme Ã©chelle, ce qui facilite l'apprentissage des modÃ¨les de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09090909, 0.125     , 0.06716981, ..., 0.81818182, 0.4       ,\n",
       "        1.        ],\n",
       "       [0.09090909, 0.28125   , 0.17207547, ..., 1.        , 0.26666667,\n",
       "        1.        ],\n",
       "       [0.06060606, 0.125     , 0.03622642, ..., 0.09090909, 0.8       ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.06060606, 0.09375   , 0.05509434, ..., 0.45454545, 0.73333333,\n",
       "        1.        ],\n",
       "       [0.09090909, 0.3125    , 0.09886792, ..., 0.        , 0.5       ,\n",
       "        0.        ],\n",
       "       [0.06060606, 0.09375   , 0.05509434, ..., 0.81818182, 0.46666667,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer chaque variable pour qu'elle soit comprise entre 0 et 1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39873715, -1.44746357, -0.97983502, ...,  1.09962055,\n",
       "        -0.31131901,  0.69065478],\n",
       "       [-0.39873715,  0.1756067 ,  0.53363434, ...,  1.74162654,\n",
       "        -0.77455741,  0.69065478],\n",
       "       [-1.47395936, -1.44746357, -1.42625404, ..., -1.46840343,\n",
       "         1.07839619, -1.44790136],\n",
       "       ...,\n",
       "       [-1.47395936, -1.77207762, -1.15404732, ..., -0.18439144,\n",
       "         0.84677699,  0.69065478],\n",
       "       [-0.39873715,  0.50022075, -0.52252773, ..., -1.78940643,\n",
       "         0.03610979, -1.44790136],\n",
       "       [-1.47395936, -1.77207762, -1.15404732, ...,  1.09962055,\n",
       "        -0.07969981,  0.69065478]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformer les variables pour qu'elles aient une moyenne Ã©gale Ã  0 et un Ã©cart type Ã©gal Ã  1\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! Attention aux outliers. Si prÃ©sents, utiliser Robuste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.66666667, -0.65004452, ...,  0.8       ,\n",
       "        -0.2       ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.58771149, ...,  1.2       ,\n",
       "        -0.46666667,  0.        ],\n",
       "       [-1.        , -1.66666667, -1.01513802, ..., -0.8       ,\n",
       "         0.6       , -1.        ],\n",
       "       ...,\n",
       "       [-1.        , -2.        , -0.79252004, ...,  0.        ,\n",
       "         0.46666667,  0.        ],\n",
       "       [ 0.        ,  0.33333333, -0.2760463 , ..., -1.        ,\n",
       "         0.        , -1.        ],\n",
       "       [-1.        , -2.        , -0.79252004, ...,  0.8       ,\n",
       "        -0.06666667,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - CrÃ©ation de polynÃ´mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_poly = PolynomialFeatures(3).fit_transform(X)\n",
    "\n",
    "# model = LinearRegression().fit(X_poly, y)\n",
    "# y_pred =model.predict(X_poly)\n",
    "\n",
    "# plt.scatter(X, y)\n",
    "# plt.plot(X, y_pred, c='r', lw=3)\n",
    "\n",
    "\n",
    "# Normaliser variables aprÃ¨s avoir utilisÃ© les polynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the algorithm \n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fits the model on the training set\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202745.19060804116\n",
      "0.7010205915375918\n",
      "192181.1350173305\n",
      "0.7019753526438841\n"
     ]
    }
   ],
   "source": [
    "#predicts on the training set\n",
    "pred_train_lr= lr.predict(X_train)\n",
    "\n",
    "#prints the evaluation metrics - RMSE and R-squared - on the training set\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lr)))\n",
    "print(r2_score(y_train, pred_train_lr))\n",
    "\n",
    "#predicts on the training set\n",
    "pred_test_lr= lr.predict(X_test)\n",
    "\n",
    "#prints the evaluation metrics - RMSE and R-squared - on the training set\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lr))) \n",
    "print(r2_score(y_test, pred_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that the RMSE, one of the two evaluation metrics, is 194361 thousand for train data and 180996 thousand for test data. On the other hand, R-squared value is 72 percent for train data and 71.8 percent for test data, which is a good performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202745.1906784061\n",
      "0.7010205913300636\n",
      "192181.00475497087\n",
      "0.7019757566521198\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=0.01)\n",
    "\n",
    "rr.fit(X_train, y_train) \n",
    "\n",
    "pred_train_rr= rr.predict(X_train)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))\n",
    "\n",
    "print(r2_score(y_train, pred_train_rr))\n",
    "\n",
    "\n",
    "pred_test_rr= rr.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_rr))) \n",
    "\n",
    "print(r2_score(y_test, pred_test_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that the RMSE and R-squared values for the Ridge Regression model on the training data is 975 thousand and 86.7 percent, respectively. For the test data, the result for these metrics is 1017 thousand and 84 percent, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202745.19060812087\n",
      "0.7010205915373567\n",
      "192181.1299714767\n",
      "0.7019753682935865\n"
     ]
    }
   ],
   "source": [
    "model_lasso = Lasso(alpha=0.01)\n",
    "\n",
    "model_lasso.fit(X_train, y_train) \n",
    "\n",
    "pred_train_lasso= model_lasso.predict(X_train)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "\n",
    "print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "\n",
    "print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that the RMSE and R-squared values for the Lasso Regression model on the training data is 971 thousand and 86.7 percent, respectively.\n",
    "\n",
    "The results for these metrics on the test data is 1019 thousand and 84 percent, respectively. Lasso Regression can also be used for feature selection because the coeï¬ƒcients of less important features are reduced to zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204763.23774927217\n",
      "0.695039119745537\n",
      "193720.0574469525\n",
      "0.6971832785448987\n"
     ]
    }
   ],
   "source": [
    "model_enet = ElasticNet(alpha = 0.01)\n",
    "\n",
    "model_enet.fit(X_train, y_train) \n",
    "\n",
    "pred_train_enet= model_enet.predict(X_train)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_enet)))\n",
    "\n",
    "print(r2_score(y_train, pred_train_enet))\n",
    "\n",
    "\n",
    "pred_test_enet= model_enet.predict(X_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_enet)))\n",
    "\n",
    "print(r2_score(y_test, pred_test_enet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that the RMSE and R-squared value for the ElasticNet Regression model on the training data is 1352 thousand and 74 percent, respectively. The results for these metrics on the test data is 1379 thousand and 71 percent, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrÃ©ation de la pipeline (ou chaÃ®ne de transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantages:  \n",
    "1. simple Ã  utiliser  \n",
    "2. sÃ©curisÃ© (Ã©vite d'avoir des fuites de donnÃ©es ou des donnÃ©es mal transformÃ©es)  \n",
    "3. permet de faire des cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([550000., 480000., 400000., ..., 290000., 550000., 350000.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(), SGDClassifier())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nusbaumer/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nusbaumer/Documents/Projet final/data_preparation_modelisation2.ipynb Cellule 52\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=2'>3</a>\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpolynomialfeatures__degree\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msgdclassifier__penalty\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39m'\u001b[39m\u001b[39ml1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=5'>6</a>\u001b[0m }\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=7'>8</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(model, param_grid\u001b[39m=\u001b[39mparams, cv\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000043?line=9'>10</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:890\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, coef_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, intercept_init\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    863\u001b[0m     \u001b[39m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[1;32m    864\u001b[0m \n\u001b[1;32m    865\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[39m        Returns an instance of self.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    891\u001b[0m         X,\n\u001b[1;32m    892\u001b[0m         y,\n\u001b[1;32m    893\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malpha,\n\u001b[1;32m    894\u001b[0m         C\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    895\u001b[0m         loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss,\n\u001b[1;32m    896\u001b[0m         learning_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m    897\u001b[0m         coef_init\u001b[39m=\u001b[39;49mcoef_init,\n\u001b[1;32m    898\u001b[0m         intercept_init\u001b[39m=\u001b[39;49mintercept_init,\n\u001b[1;32m    899\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    900\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:686\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[39m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_ \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m--> 686\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_fit(\n\u001b[1;32m    687\u001b[0m     X,\n\u001b[1;32m    688\u001b[0m     y,\n\u001b[1;32m    689\u001b[0m     alpha,\n\u001b[1;32m    690\u001b[0m     C,\n\u001b[1;32m    691\u001b[0m     loss,\n\u001b[1;32m    692\u001b[0m     learning_rate,\n\u001b[1;32m    693\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    694\u001b[0m     classes,\n\u001b[1;32m    695\u001b[0m     sample_weight,\n\u001b[1;32m    696\u001b[0m     coef_init,\n\u001b[1;32m    697\u001b[0m     intercept_init,\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    700\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol \u001b[39m>\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m    703\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter\n\u001b[1;32m    704\u001b[0m ):\n\u001b[1;32m    705\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    706\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaximum number of iteration reached before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    707\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconvergence. Consider increasing max_iter to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimprove the fit.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    709\u001b[0m         ConvergenceWarning,\n\u001b[1;32m    710\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:619\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39m# delegate to concrete training procedure\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_multiclass(\n\u001b[1;32m    620\u001b[0m         X,\n\u001b[1;32m    621\u001b[0m         y,\n\u001b[1;32m    622\u001b[0m         alpha\u001b[39m=\u001b[39;49malpha,\n\u001b[1;32m    623\u001b[0m         C\u001b[39m=\u001b[39;49mC,\n\u001b[1;32m    624\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    625\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    626\u001b[0m         max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[1;32m    627\u001b[0m     )\n\u001b[1;32m    628\u001b[0m \u001b[39melif\u001b[39;00m n_classes \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_binary(\n\u001b[1;32m    630\u001b[0m         X,\n\u001b[1;32m    631\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m         max_iter\u001b[39m=\u001b[39mmax_iter,\n\u001b[1;32m    637\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:763\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit_multiclass\u001b[0;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[1;32m    761\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    762\u001b[0m seeds \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mrandint(MAX_INT, size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_))\n\u001b[0;32m--> 763\u001b[0m result \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    764\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, require\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msharedmem\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    765\u001b[0m )(\n\u001b[1;32m    766\u001b[0m     delayed(fit_binary)(\n\u001b[1;32m    767\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    768\u001b[0m         i,\n\u001b[1;32m    769\u001b[0m         X,\n\u001b[1;32m    770\u001b[0m         y,\n\u001b[1;32m    771\u001b[0m         alpha,\n\u001b[1;32m    772\u001b[0m         C,\n\u001b[1;32m    773\u001b[0m         learning_rate,\n\u001b[1;32m    774\u001b[0m         max_iter,\n\u001b[1;32m    775\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_expanded_class_weight[i],\n\u001b[1;32m    776\u001b[0m         \u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    777\u001b[0m         sample_weight,\n\u001b[1;32m    778\u001b[0m         validation_mask\u001b[39m=\u001b[39;49mvalidation_mask,\n\u001b[1;32m    779\u001b[0m         random_state\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    780\u001b[0m     )\n\u001b[1;32m    781\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, seed \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(seeds)\n\u001b[1;32m    782\u001b[0m )\n\u001b[1;32m    784\u001b[0m \u001b[39m# take the maximum of n_iter_ over every binary fit\u001b[39;00m\n\u001b[1;32m    785\u001b[0m n_iter_ \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:456\u001b[0m, in \u001b[0;36mfit_binary\u001b[0;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[1;32m    452\u001b[0m seed \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mrandint(MAX_INT)\n\u001b[1;32m    454\u001b[0m tol \u001b[39m=\u001b[39m est\u001b[39m.\u001b[39mtol \u001b[39mif\u001b[39;00m est\u001b[39m.\u001b[39mtol \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[0;32m--> 456\u001b[0m coef, intercept, average_coef, average_intercept, n_iter_ \u001b[39m=\u001b[39m _plain_sgd(\n\u001b[1;32m    457\u001b[0m     coef,\n\u001b[1;32m    458\u001b[0m     intercept,\n\u001b[1;32m    459\u001b[0m     average_coef,\n\u001b[1;32m    460\u001b[0m     average_intercept,\n\u001b[1;32m    461\u001b[0m     est\u001b[39m.\u001b[39;49mloss_function_,\n\u001b[1;32m    462\u001b[0m     penalty_type,\n\u001b[1;32m    463\u001b[0m     alpha,\n\u001b[1;32m    464\u001b[0m     C,\n\u001b[1;32m    465\u001b[0m     est\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[1;32m    466\u001b[0m     dataset,\n\u001b[1;32m    467\u001b[0m     validation_mask,\n\u001b[1;32m    468\u001b[0m     est\u001b[39m.\u001b[39;49mearly_stopping,\n\u001b[1;32m    469\u001b[0m     validation_score_cb,\n\u001b[1;32m    470\u001b[0m     \u001b[39mint\u001b[39;49m(est\u001b[39m.\u001b[39;49mn_iter_no_change),\n\u001b[1;32m    471\u001b[0m     max_iter,\n\u001b[1;32m    472\u001b[0m     tol,\n\u001b[1;32m    473\u001b[0m     \u001b[39mint\u001b[39;49m(est\u001b[39m.\u001b[39;49mfit_intercept),\n\u001b[1;32m    474\u001b[0m     \u001b[39mint\u001b[39;49m(est\u001b[39m.\u001b[39;49mverbose),\n\u001b[1;32m    475\u001b[0m     \u001b[39mint\u001b[39;49m(est\u001b[39m.\u001b[39;49mshuffle),\n\u001b[1;32m    476\u001b[0m     seed,\n\u001b[1;32m    477\u001b[0m     pos_weight,\n\u001b[1;32m    478\u001b[0m     neg_weight,\n\u001b[1;32m    479\u001b[0m     learning_rate_type,\n\u001b[1;32m    480\u001b[0m     est\u001b[39m.\u001b[39;49meta0,\n\u001b[1;32m    481\u001b[0m     est\u001b[39m.\u001b[39;49mpower_t,\n\u001b[1;32m    482\u001b[0m     \u001b[39m0\u001b[39;49m,\n\u001b[1;32m    483\u001b[0m     est\u001b[39m.\u001b[39;49mt_,\n\u001b[1;32m    484\u001b[0m     intercept_decay,\n\u001b[1;32m    485\u001b[0m     est\u001b[39m.\u001b[39;49maverage,\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m est\u001b[39m.\u001b[39maverage:\n\u001b[1;32m    489\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(est\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trouver les meilleurs paramÃ¨tres de la pipeline\n",
    "model = make_pipeline(PolynomialFeatures(), StandardScaler(), SGDClassifier(random_state=0))\n",
    "params = {\n",
    "    'polynomialfeatures__degree' : [2, 3, 4],\n",
    "    'sgdclassifier__penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid=params, cv=4)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nusbaumer/Documents/Projet final/data_preparation_modelisation2.ipynb Cellule 53\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000044?line=0'>1</a>\u001b[0m grid\u001b[39m.\u001b[39;49mbest_params_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nusbaumer/Documents/Projet final/data_preparation_modelisation2.ipynb Cellule 54\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000045?line=0'>1</a>\u001b[0m grid\u001b[39m.\u001b[39;49mscore(X_test, y_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:437\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"Return the score on the given data, if the estimator has been refit.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[39mThis uses the score defined by ``scoring`` where provided, and the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    ``best_estimator_.score`` method otherwise.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m _check_refit(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 437\u001b[0m check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscorer_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo score function explicitly defined, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand the estimator doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt provide one \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\n\u001b[1;32m    443\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/utils/validation.py:1345\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1341\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1342\u001b[0m     ]\n\u001b[1;32m   1344\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'LinearRegression()' (type <class 'sklearn.linear_model._base.LinearRegression'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nusbaumer/Documents/Projet final/data_preparation_modelisation2.ipynb Cellule 55\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000017?line=0'>1</a>\u001b[0m my_pipe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 378\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/pipeline.py:316\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps):\n\u001b[1;32m    314\u001b[0m     \u001b[39m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps)\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Setup the memory\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     memory \u001b[39m=\u001b[39m check_memory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/pipeline.py:207\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[1;32m    205\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[0;32m--> 207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    214\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    216\u001b[0m     estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    219\u001b[0m ):\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'LinearRegression()' (type <class 'sklearn.linear_model._base.LinearRegression'>) doesn't"
     ]
    }
   ],
   "source": [
    "my_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f37351fa8c0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Avec l'estimator\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "estimator = SVC(gamma=0.001)\n",
    "\n",
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=30,return_times=True)\n",
    "\n",
    "plt.plot(train_sizes,np.mean(train_scores,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3734fd1f00>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Avec Ridge Regression (rr)\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "estimator = SVC(gamma=0.001)\n",
    "\n",
    "train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(rr, X, y, cv=30,return_times=True)\n",
    "\n",
    "plt.plot(train_sizes,np.mean(train_scores,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RÃ©sultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/nusbaumer/Documents/Projet final/data_preparation_modelisation2.ipynb Cellule 60\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nusbaumer/Documents/Projet%20final/data_preparation_modelisation2.ipynb#ch0000019?line=0'>1</a>\u001b[0m my_pipe\u001b[39m.\u001b[39;49mscore(X_test, y_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/utils/metaestimators.py:127\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m    121\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[1;32m    128\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m    129\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/nnp/lib/python3.10/site-packages/sklearn/pipeline.py:46\u001b[0m, in \u001b[0;36m_final_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[39m# raise original `AttributeError` if `attr` does not exist\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator, attr)\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "my_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The performance of the models is summarized below:  \n",
    " \n",
    "    Linear Regression Model: Test set RMSE of 1019 thousand and R-square of 83.96 percent.  \n",
    "\n",
    "    Ridge Regression Model: Test set RMSE of 1017 thousand and R-square of 84.02 percent.  \n",
    "\n",
    "    Lasso Regression Model: Test set RMSE of 1019 thousand and R-square of 83.96 percent.  \n",
    "    \n",
    "    ElasticNet Regression Model: Test set RMSE of 1379 thousand and R-square of 70.62 percent.  \n",
    "\n",
    "The ElasticNet Regression model is performing the worst. All the other regression models are performing better with a decent R-squared and stable RMSE values. The most ideal result would be an RMSE value of zero and R-squared value of 1, but that's almost impossible in real economic datasets.  \n",
    "\n",
    "There are other iterations that can be done to improve model performance. We have assigned the value of alpha to be 0.01, but this can be altered by hyper parameter tuning to arrive at the optimal alpha value. Cross-validation can also be tried along with feature selection techniques. However, that is not covered in this guide which was aimed at enabling individuals to understand and implement the various Linear Regression models using the scikit-learn library. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nnp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f720d1ff3bc865cea1f3319b2feaa346936005ee2384c21dd0606ac777c86dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
